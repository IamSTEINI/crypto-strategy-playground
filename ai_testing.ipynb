{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8f47a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e7f10999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "data = [[1.0,2.0,3.0], [4.0,5.0,6.0]]\n",
    "tensor = torch.tensor(data, requires_grad=True)\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7fb3f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[-0.3561,  0.3919, -0.5935],\n",
      "        [-0.7443,  0.0166,  0.3884]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "ones = torch.ones(shape)\n",
    "zeros = torch.zeros(shape)\n",
    "random = torch.randn(shape)\n",
    "\n",
    "print(ones)\n",
    "print(zeros)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3c24943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60., grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x000001C14E4CB0A0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(4.0, requires_grad=True)\n",
    "x = torch.tensor(10., requires_grad=True)\n",
    "\n",
    "y = a + b\n",
    "z = x * y\n",
    "\n",
    "print(z)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "872bfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  8.],\n",
      "        [ 3., 32.]])\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2.],[3.,4.]])\n",
    "b = torch.tensor([[5.,4.],[1.,8.]])\n",
    "\n",
    "c = a * b\n",
    "print(c)\n",
    "print(a.mean(dim=0))\n",
    "print(a.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ac80fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([ 2,  6, 10])\n",
      "tensor([3, 3, 3])\n",
      "tensor([[ 0],\n",
      "        [ 6],\n",
      "        [11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3,4)\n",
    "col = x[:, 2]\n",
    "print(x)\n",
    "print(col)\n",
    "print(torch.argmax(x, dim=1))\n",
    "print(torch.gather(x, dim=1, index=torch.tensor([[0], [2], [3]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3f0d6c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init. W: tensor([[-1.2910]], requires_grad=True)\n",
      "Init. b: tensor([-0.5111], requires_grad=True)\n",
      "Prediction y hat: tensor([[-1.0922],\n",
      "        [-1.8029],\n",
      "        [ 0.4534]], grad_fn=<SliceBackward0>)\n",
      "True y: tensor([[ 1.9382],\n",
      "        [ 2.9751],\n",
      "        [-0.5206]])\n",
      "LOSS: 13.552383422851562\n",
      "tensor([[-6.9616]])\n",
      "tensor([-2.7983])\n",
      "EPOCH: 00 \\ Loss: 0.1588, W: 1.663, b: 0.830\n",
      "EPOCH: 10 \\ Loss: 0.1079, W: 1.724, b: 0.865\n",
      "EPOCH: 20 \\ Loss: 0.0744, W: 1.773, b: 0.894\n",
      "EPOCH: 30 \\ Loss: 0.0522, W: 1.813, b: 0.918\n",
      "EPOCH: 40 \\ Loss: 0.0375, W: 1.844, b: 0.938\n",
      "EPOCH: 50 \\ Loss: 0.0277, W: 1.870, b: 0.955\n",
      "EPOCH: 60 \\ Loss: 0.0213, W: 1.891, b: 0.968\n",
      "EPOCH: 70 \\ Loss: 0.0170, W: 1.908, b: 0.980\n",
      "EPOCH: 80 \\ Loss: 0.0142, W: 1.921, b: 0.989\n",
      "EPOCH: 90 \\ Loss: 0.0123, W: 1.932, b: 0.997\n",
      "EPOCH: 100 \\ Loss: 0.0111, W: 1.941, b: 1.003\n",
      "EPOCH: 110 \\ Loss: 0.0102, W: 1.948, b: 1.009\n",
      "EPOCH: 120 \\ Loss: 0.0097, W: 1.954, b: 1.013\n",
      "EPOCH: 130 \\ Loss: 0.0093, W: 1.959, b: 1.017\n",
      "EPOCH: 140 \\ Loss: 0.0091, W: 1.963, b: 1.020\n",
      "EPOCH: 150 \\ Loss: 0.0089, W: 1.966, b: 1.022\n",
      "EPOCH: 160 \\ Loss: 0.0088, W: 1.968, b: 1.024\n",
      "EPOCH: 170 \\ Loss: 0.0087, W: 1.970, b: 1.026\n",
      "EPOCH: 180 \\ Loss: 0.0087, W: 1.972, b: 1.027\n",
      "EPOCH: 190 \\ Loss: 0.0087, W: 1.973, b: 1.029\n",
      "EPOCH: 200 \\ Loss: 0.0086, W: 1.974, b: 1.030\n",
      "EPOCH: 210 \\ Loss: 0.0086, W: 1.975, b: 1.030\n",
      "EPOCH: 220 \\ Loss: 0.0086, W: 1.976, b: 1.031\n",
      "EPOCH: 230 \\ Loss: 0.0086, W: 1.976, b: 1.032\n",
      "EPOCH: 240 \\ Loss: 0.0086, W: 1.977, b: 1.032\n",
      "EPOCH: 250 \\ Loss: 0.0086, W: 1.977, b: 1.032\n",
      "EPOCH: 260 \\ Loss: 0.0086, W: 1.978, b: 1.033\n",
      "EPOCH: 270 \\ Loss: 0.0086, W: 1.978, b: 1.033\n",
      "EPOCH: 280 \\ Loss: 0.0086, W: 1.978, b: 1.033\n",
      "EPOCH: 290 \\ Loss: 0.0086, W: 1.978, b: 1.033\n",
      "EPOCH: 300 \\ Loss: 0.0086, W: 1.978, b: 1.033\n",
      "EPOCH: 310 \\ Loss: 0.0086, W: 1.978, b: 1.034\n",
      "EPOCH: 320 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 330 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 340 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 350 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 360 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 370 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 380 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 390 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 400 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 410 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 420 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 430 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 440 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 450 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 460 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 470 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 480 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 490 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 500 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 510 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 520 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 530 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 540 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 550 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 560 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 570 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 580 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 590 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 600 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 610 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 620 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 630 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 640 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 650 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 660 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 670 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 680 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 690 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 700 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 710 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 720 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 730 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 740 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 750 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 760 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 770 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 780 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 790 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 800 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 810 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 820 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 830 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 840 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 850 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 860 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 870 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 880 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 890 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 900 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 910 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 920 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 930 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 940 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 950 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 960 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 970 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 980 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "EPOCH: 990 \\ Loss: 0.0086, W: 1.979, b: 1.034\n",
      "FINAL PARAMETERS: W=1.979, b=1.034\n",
      "True params: W=2, b=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\Stein\\AppData\\Local\\Temp\\ipykernel_4720\\218697554.py:49: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f'EPOCH: {epoch:02d} \\ Loss: {loss.item():.4f}, W: {W.item():.3f}, b: {b.item():.3f}')\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "D_in = 1\n",
    "D_out = 1\n",
    "X = torch.randn(N,D_in)\n",
    "\n",
    "true_W = torch.tensor([[2.0]])\n",
    "true_b = torch.tensor(1.0)\n",
    "y = X @ true_W + true_b + torch.randn(N, D_out) * 0.1\n",
    "\n",
    "W = torch.randn(D_in, D_out, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "print(f\"Init. W: {W}\")\n",
    "print(f\"Init. b: {b}\")\n",
    "\n",
    "def model(X):\n",
    "    return X @ W + b\n",
    "\n",
    "y_hat = model(X)\n",
    "\n",
    "print(f\"Prediction y hat: {y_hat[:3]}\")\n",
    "print(f\"True y: {y[:3]}\")\n",
    "\n",
    "error = y_hat - y\n",
    "squared_error = error ** 2\n",
    "loss = squared_error.mean()\n",
    "\n",
    "print(f\"LOSS: {loss}\")\n",
    "\n",
    "loss.backward()\n",
    "print(W.grad)\n",
    "print(b.grad)\n",
    "\n",
    "learning_rate, epochs = 0.01, 1000\n",
    "W, b = torch.randn(1,1,requires_grad=True), torch.rand(1, requires_grad=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_hat = X @ W + b\n",
    "    loss = torch.mean((y_hat - y) ** 2)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "    \n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'EPOCH: {epoch:02d} \\ Loss: {loss.item():.4f}, W: {W.item():.3f}, b: {b.item():.3f}')\n",
    "\n",
    "print(f'FINAL PARAMETERS: W={W.item():.3f}, b={b.item():.3f}')\n",
    "print(f'True params: W=2, b=1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
